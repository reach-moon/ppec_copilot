import streamlit as st
import requests
import json
import uuid
from datetime import datetime
from typing import List, Dict, Any

# Streamlit app configuration
st.set_page_config(page_title="PPEC Copilot - Streamlit Client", page_icon="ğŸ¤–", layout="wide")

# App title
st.title("ğŸ¤– PPEC Copilot - Streamlit Client")

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯ PPEC Copilotï¼Œæ‚¨çš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ"}]

# Sidebar for settings
st.sidebar.header("âš™ï¸ è®¾ç½®")
base_url = st.sidebar.text_input("Backend API URL", "http://127.0.0.1:8000")
endpoint = st.sidebar.selectbox("é€‰æ‹©æ¥å£", [
    "/api/v1/ragflow-stream", 
    "/api/v1/chat/completions"
])
stream_enabled = st.sidebar.checkbox("å¯ç”¨æµå¼ä¼ è¾“", value=True)
session_id = st.sidebar.text_input("ä¼šè¯ ID", "streamlit_session")
model_name = st.sidebar.text_input("æ¨¡å‹åç§°", "qwen")

# Display chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# User input
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # Add user message to session state
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Add assistant response to session state
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        reasoning_content = ""
        assistant_message_container = None
        reasoning_container = None
        
        if stream_enabled:
            # Streaming response
            try:
                with st.spinner("æ­£åœ¨è·å–å›ç­”..."):
                    if endpoint == "/api/v1/chat/completions" or endpoint == "/api/v1/ragflow-stream":
                        # ä½¿ç”¨æ–°çš„ç»Ÿä¸€æ¥å£æ ¼å¼
                        response = requests.post(
                            f"{base_url}{endpoint}",
                            json={
                                "model": model_name,
                                "messages": [
                                    {"role": "user", "content": prompt}
                                ],
                                "stream": True
                            },
                            stream=True,
                            timeout=60
                        )
                    else:
                        # ä½¿ç”¨åŸæœ‰çš„æ¥å£æ ¼å¼
                        response = requests.post(
                            f"{base_url}{endpoint}",
                            json={
                                "session_id": session_id,
                                "message": prompt
                            },
                            stream=True,
                            timeout=60
                        )
                    response.raise_for_status()
                    
                    for line in response.iter_lines():
                        if line:
                            try:
                                decoded_line = line.decode('utf-8')
                                if decoded_line.startswith('data: '):
                                    data_str = decoded_line[6:]  # Remove 'data: ' prefix
                                    if data_str == '[DONE]':
                                        continue
                                        
                                    try:
                                        data = json.loads(data_str)
                                        
                                        # Handle OpenAI format (with choices and delta)
                                        if 'choices' in data and len(data['choices']) > 0:
                                            delta = data['choices'][0].get('delta', {})
                                            
                                            # Handle reasoning_content
                                            if 'reasoning_content' in delta and delta['reasoning_content']:
                                                reasoning_content += delta['reasoning_content']
                                                # Create or update reasoning container
                                                if reasoning_container is None:
                                                    reasoning_container = st.empty()
                                                reasoning_container.info(f"**ğŸ§  æ·±åº¦æ€è€ƒ:**\n\n{reasoning_content}")
                                            
                                            # Handle content
                                            if 'content' in delta and delta['content']:
                                                full_response += delta['content']
                                                # Create or update assistant message container
                                                if assistant_message_container is None:
                                                    assistant_message_container = st.empty()
                                                assistant_message_container.markdown(full_response + "â–Œ")
                                        # Handle simple format for backward compatibility
                                        elif 'content' in data and data['content']:
                                            full_response += data['content']
                                            # Create or update assistant message container
                                            if assistant_message_container is None:
                                                assistant_message_container = st.empty()
                                            assistant_message_container.markdown(full_response + "â–Œ")
                                            
                                    except json.JSONDecodeError:
                                        # Handle non-JSON lines
                                        continue
                            except Exception as e:
                                st.error(f"å¤„ç†æµæ•°æ®æ—¶å‡ºé”™: {e}")
                                break
                
                # Finalize the response without cursor
                if assistant_message_container is not None:
                    assistant_message_container.markdown(full_response)
                
            except requests.exceptions.RequestException as e:
                st.error(f"è¯·æ±‚å‡ºé”™: {e}")
                full_response = "æŠ±æ­‰ï¼Œè¯·æ±‚å‡ºé”™ï¼Œè¯·ç¨åå†è¯•ã€‚"
                if assistant_message_container is None:
                    assistant_message_container = st.empty()
                assistant_message_container.markdown(full_response)
        else:
            # Non-streaming response
            try:
                if endpoint == "/api/v1/chat/completions" or endpoint == "/api/v1/ragflow-stream":
                    # ä½¿ç”¨æ–°çš„ç»Ÿä¸€æ¥å£æ ¼å¼
                    response = requests.post(
                        f"{base_url}{endpoint}",
                        json={
                            "model": model_name,
                            "messages": [
                                {"role": "user", "content": prompt}
                            ],
                            "stream": False
                        },
                        timeout=60
                    )
                else:
                    # ä½¿ç”¨åŸæœ‰çš„æ¥å£æ ¼å¼
                    response = requests.post(
                        f"{base_url}{endpoint}",
                        json={
                            "session_id": session_id,
                            "message": prompt
                        },
                        timeout=60
                    )
                response.raise_for_status()
                # For non-streaming, we just display the full response
                full_response = response.text
                if assistant_message_container is None:
                    assistant_message_container = st.empty()
                assistant_message_container.markdown(full_response)
            except requests.exceptions.RequestException as e:
                st.error(f"è¯·æ±‚å‡ºé”™: {e}")
                full_response = "æŠ±æ­‰ï¼Œè¯·æ±‚å‡ºé”™ï¼Œè¯·ç¨åå†è¯•ã€‚"
                if assistant_message_container is None:
                    assistant_message_container = st.empty()
                assistant_message_container.markdown(full_response)
        
        # Add assistant response to session state
        # Combine reasoning and content for session state
        combined_response = ""
        if reasoning_content:
            combined_response += f"**ğŸ§  æ·±åº¦æ€è€ƒ:**\n\n{reasoning_content}\n\n"
        if full_response:
            combined_response += f"**å›ç­”:**\n\n{full_response}"
            
        st.session_state.messages.append({"role": "assistant", "content": combined_response})

# Add a button to clear chat history
if st.sidebar.button("æ¸…ç©ºèŠå¤©è®°å½•"):
    st.session_state.messages = [{"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯ PPEC Copilotï¼Œæ‚¨çš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ"}]
    st.rerun()